import pandas as pdimport numpy as npimport matplotlib.pylab as pltfrom statsmodels.tsa.stattools import acffrom scipy.stats import pearsonrfrom utils import read_data, symbols, returns, consolidate_datapd.options.display.float_format = '{:,.5f}'.formatimport seaborn as snssns.set(font_scale=1)sns.set_style("white")"""Stylized Fact #1: Absence of (linear) autocorrelation"""def autocorrelation(nlags=30, absolute=False):    lag_1_trues = 0    lag_2_trues = 0    threshold = 0.05    lags = [i for i in range(0,nlags+1)]    results = {}    for sym in symbols:        # Read the daily data        d = read_data(sym, stl=False)        rets = returns(d['price'])        if absolute:            rets = np.abs(rets)        # Calculate the linear autocorrelations        res, confint, qstat, pvals = acf(rets, nlags=nlags, fft=True,                                         qstat=True, alpha=0.05)        pvals = pvals                plt.scatter(lags,res, cmap=sym, label=sym) #c=pvals, cmap='bwr')        results[sym] = res        lag_1 = np.abs(res[0]) < threshold        lag_1_trues += lag_1        lag_2 = np.abs(res[1]) < threshold        lag_2_trues += lag_2                print(f"{sym} 1-lag |acf| under .10: {lag_1}")        print(f"{sym} 1-lag |acf| under .10: {lag_2}")    plt.legend(loc='upper right')    plt.axhline(y=0, color='b')    plt.axhline(y = 0.1, color = 'pink', linestyle = '-')    plt.axhline(y = -0.1, color = 'pink', linestyle = '-')    plt.axhline(y = 0.05, color = 'cornflowerblue', linestyle = '--')    plt.axhline(y = -0.05, color = 'cornflowerblue', linestyle = '--')    plt.title("Autocorrelation")    plt.xlabel('lag (days)')    plt.ylabel('acf')    plt.show()    print(f"overall 1-lag true: {lag_1_trues} out of {len(symbols)}")    print(f"overall 2-lag true: {lag_2_trues} out of {len(symbols)}")  """Stylized Facts #6 and 8: Volatility clustering (absolute autocorrelation)"""      def volatility_clustering(nlags=100, threshold_1=0.1, threshold_2=.01):        lags = [i for i in range(0,nlags+1)]    results = {}    for sym in symbols:        # Read the daily data        d = read_data(sym)                # Calculate volatility        rets = returns(d['price'])        abs_rets = np.abs(rets)        # Calculate the absolute autocorrelation        res_l = acf(rets, nlags=nlags, fft=True )        res, confint, qstat, pvals = acf(abs_rets, nlags=nlags, fft=True,                                         qstat=True, alpha=0.05)        pvals = pvals                # Plot the autocorrelation values        plt.scatter(lags,res, cmap=sym, label=sym)        i = 0        for r in res[1:]:            if r > threshold_1:                i += 1            else:                break        j = 0        for r in res[1:]:            if r > threshold_2:                j += 1            else:                break        results[sym] = {"abs 1lag": res[1], "lin 1lag": res_l[1],                        f"count {threshold_1}": i, f"count {threshold_2}": j,                        "multiple": res[1]/abs(res_l[1])}            plt.legend(loc='upper right')    plt.axhline(y = 0.1, color = 'pink', linestyle = '-')    plt.axhline(y = 0.05, color = 'cornflowerblue', linestyle = '--')    plt.axhline(y=0, color='b')    plt.title("Autocorrelation of Absolute Returns")    plt.xlabel('lag (days)')    plt.ylabel('acf')    plt.show()    # Print the summarized results    df = pd.DataFrame(results).transpose()    print(df)    return df"""Stylized Facts #6 and 8: Alternate version to plot the absoluteautocorrelation on a log-log scale. Used to assess whether decay followspower-law versus exponential decay."""  def volatility_clustering_log(nlags=100, threshold=0.1):    rows = int(np.ceil(len(symbols) / 2))    fig, axs = plt.subplots(rows, 2, figsize=(30,25))    x = 0    y = 0    lags = [i for i in range(1,nlags+1)]    results = {}    for sym in symbols:        d = read_data(sym)        rets = returns(d['price'])        abs_rets = np.abs(rets)        res_l = acf(rets, nlags=nlags, fft=True )        res, confint, qstat, pvals = acf(abs_rets, nlags=nlags, fft=True,                                         qstat=True, alpha=0.05)        res = res[1:]        pvals = pvals        r = pd.DataFrame({"x":lags, "y":res})        sns.scatterplot(ax=axs[y,x], data=r, y='y', x='x',                     palette=sns.color_palette('bright'))                axs[y,x].set_title(f"{sym}", size=20)        axs[y,x].set_xlabel('lag (days)')        axs[y,x].set_ylabel('acf')        axs[y,x].set_yscale('log')        axs[y,x].set_xscale('log')        if y != 4:            axs[y,x].set_xlabel(None)        if x == 0:            x = 1        else:            x = 0            y = y + 1        i = 0        for r in res:            if r > threshold:                i += 1            else:                break        results[sym] = {"count": i, "multiple": res[0]/abs(res_l[1])}            plt.show()    print(pd.DataFrame(results).transpose())"""Stylized Facts #9: Leverage Effect"""  def leverage_effect(nlags=10, threshold=0.1):    results = {}    for sym in symbols:        res = {}        # Read the daily data        d = read_data(sym, stl=False)                # Calculate the volatility        rets = returns(d['price'])        abs_rets = np.square(rets)        # Calculate the correlation of returns and lagged volatility        # for lags of -1, 0, and 1        x = rets[1:]        y = abs_rets[:-1]        corr, pval = pearsonr(x, y)        res["$\tau=-1$ corr"] = corr        res["$\tau=-1$ pval"] = pval                x = rets        y = abs_rets        corr, pval = pearsonr(x, y)        res["$\tau=0$ corr"] = corr        res["$\tau=0$ pval"] = pval                x = rets[:-1]        y = abs_rets[1:]        corr, pval = pearsonr(x, y)        res["$\tau=1$ corr"] = corr        res["$\tau=1$ pval"] = pval                plt.scatter(x,y)        plt.title(sym)        plt.show()                results[sym] = res        # Print the summarized results    df = pd.DataFrame(results).transpose()    print(df.to_string())    return df    """Stylized Facts #10: Volume/Volatility correlation"""      def volume_volatility(nlags=10, threshold=0.1):    results = {}    for sym in symbols:        # Read the daily data        d = read_data(sym)                # Calculate the volatility        rets = returns(d['price'])        abs_rets = np.abs(rets)                # Calculate the correlation between volume and volatility        volume = d['Volume'][1:]        plt.scatter(abs_rets,volume)        corr, pval = pearsonr(abs_rets, volume)                # Plot volume versus volatility        plt.title(sym)        plt.xlabel('Absolute return')        plt.ylabel('Total shares traded')        plt.show()        results[sym] = {"Correlation": corr, "P-value": pval}        # Print the summarized results    df = pd.DataFrame(results).transpose()    print(df.to_string())    return df"""Stylized Facts #11: Asymmetry in timescales"""  def timescale_asymmetry(nlags=10, stl=False):    for period in ['W']:        if period == 'W':            p_name = "Weekly"            periods = "weeks"        else:            p_name = "Monthly"            periods = "months"        results = {}        lags = [i - 10 for i in range(nlags*2+1)]        for sym in symbols:            corr_vals = {}            # Read the daily data            d = read_data(sym, stl=stl)            d['return'] = np.square(returns(d['price']))                    # Get the average daily volatility for each period            res = []            df = d.copy()            df = (                df.resample(period).agg({"return": "mean"})            )                        # Read the aggregated data            agg = consolidate_data(sym, period=period, stl=stl)                        # Calculate the volatility for each period            agg_rets = np.square(returns(agg['price']))                        # Set x to be the fine volatility, y the coarse volatility            x = df['return'][1:]            y = agg_rets                        # Calculate the correlation for positive and negative lags of y            # relative to x            for lag in lags:                l = abs(lag)                if lag < 0:                    xl = x[l:] # lag daily returns                    yl = y[:-l] # remove last l entries of coarse returns                else:                    if lag == 0:                        xl = x                    else:                        xl = x[:-l] # remove last l entries of daily returns                    yl = y[l:] # lag coarse returns                corr, pval = pearsonr(xl, yl)                res.append(corr)                if abs(lag)<2:                    corr_vals[lag] = corr                        # Calculate the difference between y lagged by 1 versus -1            corr_vals['diff'] = corr_vals[1] - corr_vals[-1]            # plot the results            plt.plot(lags, res, "-o")            plt.title(f"{sym} Avg. Squared Returns: Daily vs Lagged {p_name} ")            diff_lag = [i for i in range(nlags+1)]            diffs = []            for i in diff_lag:                diffs.append(res[i+nlags] - res[nlags-i])            plt.plot(diff_lag,diffs, 'r--')            plt.axhline(y=0)            plt.xlabel(f"Time lag in {periods}")            plt.ylabel("Correlation")            plt.show()            results[sym] = corr_vals                # Print the summarized results        df = pd.DataFrame(results).transpose()        print(df.to_string())        return df#autocorrelation()#volatility_clustering()#volatility_clustering_log()#leverage_effect()#volume_volatility()#timescale_asymmetry()